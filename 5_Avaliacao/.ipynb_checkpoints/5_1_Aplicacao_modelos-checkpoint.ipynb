{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cfc545c-bb23-4dba-b30d-fcf480ea78e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b741f0-569d-4fb5-af78-96cb52d8c8f1",
   "metadata": {},
   "source": [
    "# Aplicação dos modelos desenvolvidos para classificação das decisões judiciais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f66b7c4-7ff9-4cc3-aaea-85fb7ba0782a",
   "metadata": {},
   "source": [
    "O processo de mineração de dados textuais de decisões judiciais elaborado resultou no desenvolvimento de dois modelos baseados em aprendizado de máquina supervisionado e na sua utilização para o processamento de mais de 20 mil decisões judiciais dos Tribunais do Trabalho da 3ª e 4ª Região. Com a utilização desses modelos, os objetivos de mineração foram atingidos que eram classificar automaticamente os acórdãos judiciais em relação ao deferimento ou não e classificar automaticamente o requerente do recurso em relação a ser empresa ou a ser empregado.\n",
    "\n",
    "Desse modo, foi possível atender também ao objetivo de negócio que seria analisar as decisões judiciais por meio de algoritmo computacional para verificar se seria possível que os tribunais avaliados e suas Turmas Recursais julgue favoravelmente quantidade significativamente maiores de recursos para uma das partes do que para outra em média."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbfb792-829c-4b0f-bf2a-96fbc256993f",
   "metadata": {},
   "source": [
    "# Carregamento da base de dados a ser processada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e91d703-ce6f-4b12-9440-9b440060deea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10875 entries, 0 to 10874\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   INDEX            10875 non-null  int64  \n",
      " 1   INTEIRO_TEOR     10875 non-null  object \n",
      " 2   DATA             10875 non-null  object \n",
      " 3   RELATOR          10875 non-null  object \n",
      " 4   ORGAO            10875 non-null  object \n",
      " 5   RECORRENTE       10875 non-null  object \n",
      " 6   DISPOSITIVO      10875 non-null  object \n",
      " 7   QTD_RECORRENTES  10875 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 679.8+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12071 entries, 0 to 12070\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   INDEX            12071 non-null  int64  \n",
      " 1   LINK             12071 non-null  object \n",
      " 2   INTEIRO_TEOR     12071 non-null  object \n",
      " 3   DATA             12071 non-null  object \n",
      " 4   RELATOR          12071 non-null  object \n",
      " 5   ORGAO            12071 non-null  object \n",
      " 6   RECORRENTE       12071 non-null  object \n",
      " 7   DISPOSITIVO      12071 non-null  object \n",
      " 8   QTD_RECORRENTES  12071 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 848.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "arquivo = \"..//3_Preparacao_dos_dados//3_1_Transformacao_dos_dados//Datasets_transformados_final//TRT3//TRT3_acordaos_amostra_2017_2018_2019_completo_com_indice_relator_limpo.csv\"\n",
    "df_trt3 = pd.read_csv( arquivo, encoding='utf-8' )\n",
    "print( df_trt3.info() )\n",
    "\n",
    "arquivo = \"..//3_Preparacao_dos_dados//3_1_Transformacao_dos_dados//Datasets_transformados_final//TRT4//TRT4_acordaos_amostra_2017_2018_2019_completo_com_indice.csv\"\n",
    "df_trt4 = pd.read_csv( arquivo, encoding='utf-8' )\n",
    "print( df_trt4.info() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ce1e985-354c-46e3-9e2e-2801d6c3603c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10875 entries, 0 to 10874\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   INDEX            10875 non-null  int64  \n",
      " 1   INTEIRO_TEOR     10875 non-null  object \n",
      " 2   DATA             10875 non-null  object \n",
      " 3   RELATOR          10875 non-null  object \n",
      " 4   ORGAO            10875 non-null  object \n",
      " 5   RECORRENTE       10875 non-null  object \n",
      " 6   DISPOSITIVO      10875 non-null  object \n",
      " 7   QTD_RECORRENTES  10875 non-null  float64\n",
      " 8   TRIBUNAL         10875 non-null  object \n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 764.8+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12071 entries, 0 to 12070\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   INDEX            12071 non-null  int64  \n",
      " 1   LINK             12071 non-null  object \n",
      " 2   INTEIRO_TEOR     12071 non-null  object \n",
      " 3   DATA             12071 non-null  object \n",
      " 4   RELATOR          12071 non-null  object \n",
      " 5   ORGAO            12071 non-null  object \n",
      " 6   RECORRENTE       12071 non-null  object \n",
      " 7   DISPOSITIVO      12071 non-null  object \n",
      " 8   QTD_RECORRENTES  12071 non-null  float64\n",
      " 9   TRIBUNAL         12071 non-null  object \n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 943.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_trt3[\"TRIBUNAL\"] = \"TRT3\"\n",
    "print( df_trt3.info() )\n",
    "\n",
    "df_trt4[\"TRIBUNAL\"] = \"TRT4\"\n",
    "print( df_trt4.info() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4860664-8d54-4078-9d96-07bc2f26531b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22946 entries, 0 to 10874\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   INDEX            22946 non-null  int64  \n",
      " 1   LINK             12071 non-null  object \n",
      " 2   INTEIRO_TEOR     22946 non-null  object \n",
      " 3   DATA             22946 non-null  object \n",
      " 4   RELATOR          22946 non-null  object \n",
      " 5   ORGAO            22946 non-null  object \n",
      " 6   RECORRENTE       22946 non-null  object \n",
      " 7   DISPOSITIVO      22946 non-null  object \n",
      " 8   QTD_RECORRENTES  22946 non-null  float64\n",
      " 9   TRIBUNAL         22946 non-null  object \n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tudo = df_trt4.copy()\n",
    "df_tudo = df_tudo.append(df_trt3)\n",
    "df_tudo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "051d2205-1544-4f4b-9597-051d79f9a226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tudo[\"QTD_RECORRENTES\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c11a0e47-ff53-41b2-b5d7-4d8098ad025d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRT4    12071\n",
       "TRT3    10875\n",
       "Name: TRIBUNAL, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tudo[\"TRIBUNAL\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c7cfc1b-df86-4211-8c05-a600ca56120e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDEX</th>\n",
       "      <th>LINK</th>\n",
       "      <th>INTEIRO_TEOR</th>\n",
       "      <th>DATA</th>\n",
       "      <th>RELATOR</th>\n",
       "      <th>ORGAO</th>\n",
       "      <th>RECORRENTE</th>\n",
       "      <th>DISPOSITIVO</th>\n",
       "      <th>QTD_RECORRENTES</th>\n",
       "      <th>TRIBUNAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4411</th>\n",
       "      <td>4411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PJe:  0011202-22.2016.5.03.0028 (RO)    Dispon...</td>\n",
       "      <td>31/10/2018</td>\n",
       "      <td>Gisele de Cassia VD Macedo</td>\n",
       "      <td>Oitava Turma</td>\n",
       "      <td>MANOEL DIAS DA ROCHA</td>\n",
       "      <td>Cabeçalho do acórdão Acórdão Fundamentos pelos...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TRT3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>4274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PJe:  0013010-59.2017.5.03.0050 (RO)    Dispon...</td>\n",
       "      <td>26/06/2018</td>\n",
       "      <td>Danilo Siqueira de C.Faria</td>\n",
       "      <td>Terceira Turma</td>\n",
       "      <td>LYND CALÇADOS LTDA.</td>\n",
       "      <td>Cabeçalho do acórdão Acórdão ACORDAM os Desemb...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TRT3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5973</th>\n",
       "      <td>5973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PJe:  0011141-96.2014.5.03.0040 (RO)    Dispon...</td>\n",
       "      <td>31/10/2018</td>\n",
       "      <td>Vitor Salino de Moura Eca</td>\n",
       "      <td>Setima Turma</td>\n",
       "      <td>MOZAR OZÓRIO DE PAULA</td>\n",
       "      <td>Cabeçalho do acórdão CONCLUSÃO Fundamentos pel...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TRT3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>3795</td>\n",
       "      <td>rest/cache/acordao/pje/p4UaytPaJzShvrGXWCkH9w?</td>\n",
       "      <td>Acórdão: 0020708-13.2015.5.04.0001 ( ROT )...</td>\n",
       "      <td>06/10/2017</td>\n",
       "      <td>CARLOS HENRIQUE SELBACH</td>\n",
       "      <td>2ª Turma</td>\n",
       "      <td>DANIELA CARVALHO DA SILVA</td>\n",
       "      <td>Vistos, relatados e discutidos os autos.  ACOR...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TRT4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4656</th>\n",
       "      <td>4656</td>\n",
       "      <td>rest/cache/acordao/pje/_Td3sG0hsYujsPloADZYSg?</td>\n",
       "      <td>Acórdão: 0020524-96.2017.5.04.0030 ( ROT )...</td>\n",
       "      <td>22/05/2019</td>\n",
       "      <td>LUIS CARLOS PINTO GASTAL</td>\n",
       "      <td>3ª Turma</td>\n",
       "      <td>KATIA MARIANTE GRANJA</td>\n",
       "      <td>Vistos, relatados e discutidos os autos.  ACOR...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TRT4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      INDEX                                            LINK  \\\n",
       "4411   4411                                             NaN   \n",
       "4274   4274                                             NaN   \n",
       "5973   5973                                             NaN   \n",
       "3795   3795  rest/cache/acordao/pje/p4UaytPaJzShvrGXWCkH9w?   \n",
       "4656   4656  rest/cache/acordao/pje/_Td3sG0hsYujsPloADZYSg?   \n",
       "\n",
       "                                           INTEIRO_TEOR        DATA  \\\n",
       "4411  PJe:  0011202-22.2016.5.03.0028 (RO)    Dispon...  31/10/2018   \n",
       "4274  PJe:  0013010-59.2017.5.03.0050 (RO)    Dispon...  26/06/2018   \n",
       "5973  PJe:  0011141-96.2014.5.03.0040 (RO)    Dispon...  31/10/2018   \n",
       "3795      Acórdão: 0020708-13.2015.5.04.0001 ( ROT )...  06/10/2017   \n",
       "4656      Acórdão: 0020524-96.2017.5.04.0030 ( ROT )...  22/05/2019   \n",
       "\n",
       "                         RELATOR           ORGAO                 RECORRENTE  \\\n",
       "4411  Gisele de Cassia VD Macedo    Oitava Turma       MANOEL DIAS DA ROCHA   \n",
       "4274  Danilo Siqueira de C.Faria  Terceira Turma        LYND CALÇADOS LTDA.   \n",
       "5973   Vitor Salino de Moura Eca    Setima Turma      MOZAR OZÓRIO DE PAULA   \n",
       "3795     CARLOS HENRIQUE SELBACH        2ª Turma  DANIELA CARVALHO DA SILVA   \n",
       "4656    LUIS CARLOS PINTO GASTAL        3ª Turma      KATIA MARIANTE GRANJA   \n",
       "\n",
       "                                            DISPOSITIVO  QTD_RECORRENTES  \\\n",
       "4411  Cabeçalho do acórdão Acórdão Fundamentos pelos...              1.0   \n",
       "4274  Cabeçalho do acórdão Acórdão ACORDAM os Desemb...              1.0   \n",
       "5973  Cabeçalho do acórdão CONCLUSÃO Fundamentos pel...              1.0   \n",
       "3795  Vistos, relatados e discutidos os autos.  ACOR...              1.0   \n",
       "4656  Vistos, relatados e discutidos os autos.  ACOR...              1.0   \n",
       "\n",
       "     TRIBUNAL  \n",
       "4411     TRT3  \n",
       "4274     TRT3  \n",
       "5973     TRT3  \n",
       "3795     TRT4  \n",
       "4656     TRT4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tudo.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543dfdc9-a5ac-4a47-8c03-c7724f926f8a",
   "metadata": {},
   "source": [
    "# Estrutura de dados para classificação do tipo de requerente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a989a62-f34c-4085-9684-40ace0f7fa5f",
   "metadata": {},
   "source": [
    "### Carregamento do modelo desenvolvido com o algoritmo Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec6ebceb-c313-4098-bf33-3c8ca33ec62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 752 ms, sys: 568 ms, total: 1.32 s\n",
      "Wall time: 1.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from joblib import load\n",
    "model_tipo_requerente = load('..//4_Modelagem//4_1_Classificador_tipo_recorrente//ml_model_recorrente_SVM.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42b5907-ec09-43e0-ab25-b3c6e3b60859",
   "metadata": {},
   "source": [
    "### Teste do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf2cdc67-721e-4583-89bd-b66e691ab2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMPREGADO = 1\n",
    "EMPRESA = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cae2fec-f99f-47cc-a391-b7354c3cdcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [EMPREGADO] in model_tipo_requerente.predict([\"joao da silva\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7ffe4c7-5122-4c51-a52a-4a08a64c4666",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [EMPRESA] in model_tipo_requerente.predict([\"empresa SA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6232ef9-413a-4f96-b58e-9dd503d1c608",
   "metadata": {},
   "source": [
    "# Estruturas de dados para classificação do deferimento ou não da decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b125a19-0daf-4b78-bee1-136b6e1eaada",
   "metadata": {},
   "source": [
    "## Tokenizador de palavras da lingua portuguesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68523a37-e2fa-41c8-868a-764954a979c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m spacy download pt_core_news_sm\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize the given sentence in Portuguese.\n",
    "    :param text: text to be tokenized, as a string\n",
    "    \"\"\"\n",
    "    tokenizer_regexp = r'''(?ux)\n",
    "    # the order of the patterns is important!!\n",
    "    # more structured patterns come first\n",
    "    [a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+(?:\\.[a-zA-Z0-9-]+)+|    # emails\n",
    "    (?:https?://)?\\w{2,}(?:\\.\\w{2,})+(?:/\\w+)*|                  # URLs\n",
    "    (?:[\\#@]\\w+)|                     # Hashtags and twitter user names\n",
    "    (?:[^\\W\\d_]\\.)+|                  # one letter abbreviations, e.g. E.U.A.\n",
    "    (?:[DSds][Rr][Aa]?)\\.|            # common abbreviations such as dr., sr., sra., dra.\n",
    "    (?:\\B-)?\\d+(?:[:.,]\\d+)*(?:-?\\w)*|\n",
    "        # numbers in format 999.999.999,999, possibly followed by hyphen and alphanumerics\n",
    "        # \\B- avoids picks as F-14 as a negative number\n",
    "    \\.{3,}|                           # ellipsis or sequences of dots\n",
    "    \\w+|                              # alphanumerics\n",
    "    -+|                               # any sequence of dashes\n",
    "    \\S                                # any non-space character\n",
    "    '''\n",
    "    tokenizer = RegexpTokenizer(tokenizer_regexp)\n",
    "\n",
    "    return tokenizer.tokenize(text)\n",
    "\n",
    "class PortugueseTokenizer(object):\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __call__(self, text):\n",
    "        words = tokenize( text )\n",
    "        # All tokens 'own' a subsequent space character in this tokenizer\n",
    "        spaces = [True] * len(words)\n",
    "        return Doc(self.vocab, words=words, spaces=spaces)\n",
    "\n",
    "nlp.tokenizer = PortugueseTokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c37c87a8-0a39-4ca8-aafc-0e609c97803f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3df3b188-c4da-45f2-8c94-996b7998f149",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words = stopwords[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f0106cf-633d-4be5-a392-210c6f7b5772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'a',\n",
       " 'o',\n",
       " 'que',\n",
       " 'e',\n",
       " 'é',\n",
       " 'do',\n",
       " 'da',\n",
       " 'em',\n",
       " 'um',\n",
       " 'para',\n",
       " 'com',\n",
       " 'uma',\n",
       " 'os',\n",
       " 'no',\n",
       " 'se',\n",
       " 'na',\n",
       " 'por',\n",
       " 'mais',\n",
       " 'as',\n",
       " 'dos',\n",
       " 'como',\n",
       " 'mas',\n",
       " 'ao',\n",
       " 'ele',\n",
       " 'das',\n",
       " 'à',\n",
       " 'seu',\n",
       " 'sua',\n",
       " 'ou',\n",
       " 'quando',\n",
       " 'muito',\n",
       " 'nos',\n",
       " 'já',\n",
       " 'eu',\n",
       " 'também',\n",
       " 'só',\n",
       " 'pelo',\n",
       " 'pela',\n",
       " 'até',\n",
       " 'isso',\n",
       " 'ela',\n",
       " 'entre',\n",
       " 'depois',\n",
       " 'sem',\n",
       " 'mesmo',\n",
       " 'aos',\n",
       " 'seus',\n",
       " 'quem',\n",
       " 'nas',\n",
       " 'me',\n",
       " 'esse',\n",
       " 'eles',\n",
       " 'você',\n",
       " 'essa',\n",
       " 'num',\n",
       " 'nem',\n",
       " 'suas',\n",
       " 'meu',\n",
       " 'às',\n",
       " 'minha',\n",
       " 'numa',\n",
       " 'pelos',\n",
       " 'elas',\n",
       " 'qual',\n",
       " 'nós',\n",
       " 'lhe',\n",
       " 'deles',\n",
       " 'essas',\n",
       " 'esses',\n",
       " 'pelas',\n",
       " 'este',\n",
       " 'dele',\n",
       " 'tu',\n",
       " 'te',\n",
       " 'vocês',\n",
       " 'vos',\n",
       " 'lhes',\n",
       " 'meus',\n",
       " 'minhas',\n",
       " 'teu',\n",
       " 'tua',\n",
       " 'teus',\n",
       " 'tuas',\n",
       " 'nosso',\n",
       " 'nossa',\n",
       " 'nossos',\n",
       " 'nossas',\n",
       " 'dela',\n",
       " 'delas',\n",
       " 'esta',\n",
       " 'estes',\n",
       " 'estas',\n",
       " 'aquele',\n",
       " 'aquela',\n",
       " 'aqueles',\n",
       " 'aquelas',\n",
       " 'isto',\n",
       " 'aquilo']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#codigo para tirar o \"não\" das stop words pq eu preciso dele nas funções de rotulação\n",
    "if \"não\" in nlp.Defaults.stop_words:\n",
    "    nlp.Defaults.stop_words.remove(\"não\")\n",
    "if \"dar\" in nlp.Defaults.stop_words:\n",
    "    nlp.Defaults.stop_words.remove(\"dar\")\n",
    "nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c10a0b4-ad96-4d82-b8ff-8153c6e5fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alterada esss funcao para tbm remover as stop words\n",
    "def get_lemma_form( frase ):\n",
    "    juntado = \"\"\n",
    "    for t in nlp( str( frase ) ):\n",
    "        if not t.is_stop: #remove stop words tbm\n",
    "            juntado += t.lemma_ +\" \"\n",
    "    return juntado.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45904b9b-f9f3-4182-a60e-22e18d991730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esse assert da erro, por isso eu criei a funcao limpa() abaixo.\n",
    "#assert \"dar parcial provimento\" in get_lemma_form( \"deu-se parcial provimento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c1331b3-44a1-4fc7-a78c-5fc1d6cd8c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ajuda a remover traços do texto\n",
    "def limpa( frase ):\n",
    "    import re\n",
    "    cleanString = re.sub('\\W+',' ', frase )\n",
    "    novo = \"\"\n",
    "    for w in cleanString.split( \" \" ):\n",
    "        pronomes_obliquos = [ \"me\", \"te\", \"se\", \"lhe\", \"lhes\", \"nos\", \"vos\" ]\n",
    "        if w not in pronomes_obliquos:\n",
    "            novo += \" \"+w\n",
    "    return novo.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a779a4fe-a379-40e3-8b1f-57a1b1ba2dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_tudo(frase):\n",
    "    return limpa( get_lemma_form( frase ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bbe4e7e-88c0-4555-9f1e-2137bfe4db65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer( texto ):\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    texto = nlp( str( texto ) )\n",
    "    return [ limpa_tudo( word.lemma_.lower().strip() ) if word.lemma_ != \"-PRON-\" else word.lower_ for word in texto ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60194a1-37fe-4558-9cdd-0af31b719dd6",
   "metadata": {},
   "source": [
    "### Testes das funções de limpeza de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa20cbb4-d7d9-49cc-822a-b33a67fa84d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'dar provimento' in limpa_tudo( \"dar provimento\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "140dc384-5223-48db-8184-45a67ca00454",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'dar parcial provimento' in limpa_tudo(\"dar parcial provimento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6862700-04e9-48d9-954d-8d69a5d8bb5d",
   "metadata": {},
   "source": [
    "# Erro no assert\n",
    "Se ocorrer erro no assert (provavelmente ocorrerá) é porque deu algum problema no carregamento das stopwords dentro do Spacy.\n",
    "<br><strong>Solução: reexecutar as células a partir do título \"Tokenizador de palavras da lingua portuguesa\" que o carregamento funcionará sem nenhuma outra intervenção. Deve haver algum bug aí na biblioteca.</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b109f5a-efd1-45c9-b02f-4ad1abb7a986",
   "metadata": {},
   "source": [
    "## Carregamento do Pipeline de vetorização dos documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2f67e58-f55a-4523-a9b6-4a0952b7fcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 179 ms, sys: 2.53 ms, total: 182 ms\n",
      "Wall time: 298 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from joblib import load\n",
    "text_transform_pipeline_deferimento = load('..//4_Modelagem//4_2_Classificador_deferimento//4_2_2_Dataset_Weak_Supervision//4_2_2_1_Com_dataset_WS_Completo//ml_text_transform_pipeline_ws_completo.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1785f7c8-8350-4735-890f-0b18d1efa963",
   "metadata": {},
   "source": [
    "## Carregamento do modelo desenvolvido com o algoritmo Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ca154e3-97d2-4674-a4b6-85833764e070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.4 ms, sys: 7.85 ms, total: 61.2 ms\n",
      "Wall time: 159 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from joblib import load\n",
    "model_deferimento = load('..//4_Modelagem//4_2_Classificador_deferimento//4_2_2_Dataset_Weak_Supervision//4_2_2_1_Com_dataset_WS_Completo//ml_model_deferimento_GradientBoostingClassifier.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487f7b2e-8256-46a2-8741-b888384916cf",
   "metadata": {},
   "source": [
    "### Teste do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d212316-3946-49b6-a7fc-a3f615b09233",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEFERIMENTO = 0\n",
    "DEFERIMENTO = 1\n",
    "SEM_ANALISE_MERITO = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55a4db9b-2edf-434c-948e-a8570cc03846",
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_dispositivo_deferimento = 'Vistos, relatados e discutidos os autos.  ACORDAM os Magistrados integrantes da 1ª Turma do Tribunal Regional do Trabalho da 4ª Região: por maioria de votos, vencidas parcialmente as Desembargadoras Relatora e Iris Lima de Moraes, com votos díspares, DAR PARCIAL PROVIMENTO AO RECURSO ORDINÁRIO DA RECLAMADA FRAS-LE S/A para [a]limitar a condenação ao pagamento de 20 minutos de horas in itinere quando a jornada se iniciava após às 23h45min e dez minutos por dia laborado pela troca de uniforme, com reflexos em repousos semanais remunerados e feriados, férias acrescidas de 1/3, 13º salário, no FGTS com a indenização de 40%; [b] excluir da condenação o pagamento de uma hora extra pela ausência de fruição integral do intervalo, pelo acréscimo do tempo de trajeto, de troca de uniforme, e de deslocamento dentro da empresa; [c] para excluir da apuração do adicional noturno as horas in itinere , o tempo de deslocamento e espera e o tempo de troca de uniforme; [d] para excluir da condenação o pagamento das horas in itinere . Valor da condenação reduzido para R$ 4.000,00, com custas proporcionais de R$ 80,00, pela reclamada.  Intime-se.  Porto Alegre, 31 de maio de 2017 (quarta-feira).          Cabeçalho do acórdão               Acórdão'\n",
    "teste_dispositivo_deferimento_vetorizado = text_transform_pipeline_deferimento.transform([teste_dispositivo_deferimento])\n",
    "assert DEFERIMENTO in model_deferimento.predict(teste_dispositivo_deferimento_vetorizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8958c828-b931-46f3-ba5d-c9c623375616",
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_dispositivo_indeferimento = 'Vistos, relatados e discutidos os autos.  ACORDAM os Magistrados integrantes da 5ª Turma do Tribunal Regional do Trabalho da 4ª Região: à unanimidade de votos, negar provimento ao recurso ordinário da reclamante.   Intime-se.  Porto Alegre, 18 de junho de 2019 (terça-feira).          Cabeçalho do acórdão               Acórdão'\n",
    "teste_dispositivo_indeferimento_vetorizado = text_transform_pipeline_deferimento.transform([teste_dispositivo_indeferimento])\n",
    "assert INDEFERIMENTO in model_deferimento.predict(teste_dispositivo_indeferimento_vetorizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4f2edbf-7159-4d2f-bbe2-3b6431a37dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_dispositivo_sem_analise_merito = \"Sem valor de condenação. Prejudicada a análise do recurso ordinário das partes.\"\n",
    "teste_dispositivo_sem_analise_merito_vetorizado = text_transform_pipeline_deferimento.transform([teste_dispositivo_sem_analise_merito])\n",
    "assert SEM_ANALISE_MERITO in model_deferimento.predict(teste_dispositivo_sem_analise_merito_vetorizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca08b0e-4bfa-4ed3-ab51-6727855162f2",
   "metadata": {},
   "source": [
    "## Vetorização dos documentos de texto das decisões"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23659014-02d5-4938-9ca1-6b1ec7f934a9",
   "metadata": {},
   "source": [
    "Primeira execução ou execução limpa: rodar as próximas duas celulas. Se quiserem abrir o array ja processado, executar a célula com o np.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b6ae54e-8b43-4b66-b068-29cf49dc2746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4h 39min 27s, sys: 3.17 s, total: 4h 39min 30s\n",
      "Wall time: 4h 39min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<22946x29087 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1903346 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dispositivo_vetorizado = text_transform_pipeline_deferimento.transform(df_tudo[\"DISPOSITIVO\"].values)\n",
    "dispositivo_vetorizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa152bf9-1bc3-46ff-a940-cc04313e9364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with open('dispositivo_vetorizado.np', 'wb') as f:\n",
    "    np.save(f, dispositivo_vetorizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e31e8c1-3713-4fba-b27d-f0adb4a258fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "\n",
    "#dispositivo_vetorizado = np.load( \"dispositivo_vetorizado.np\", allow_pickle=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4127ed-3f77-4d94-a3e3-a00e3ed18709",
   "metadata": {},
   "source": [
    "# Aplicação dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430c32bb-aa0a-4877-9981-18597138a9a2",
   "metadata": {},
   "source": [
    "### Classificação do tipo de requerente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9dbd0e73-22a8-4437-8804-a3159b3f59e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo_requerente_previsto = model_tipo_requerente.predict(df_tudo[\"RECORRENTE\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9313f2b5-27c4-46b4-8319-bfa5afeb7889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tudo[\"tipo_requerente_previsto\"] = tipo_requerente_previsto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7708d036-159b-4541-b94c-aa8712bb023d",
   "metadata": {},
   "source": [
    "### Classificação do deferimento ou não da decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70439a3c-178c-499c-b73a-aa2da9fb5233",
   "metadata": {},
   "outputs": [],
   "source": [
    "deferimento_previsto = model_deferimento.predict(dispositivo_vetorizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b42fbcb0-cd88-45c1-aef8-213552e6fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tudo[\"deferimento_previsto\"] = deferimento_previsto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "22bea15e-ac4c-4ebd-bfd6-bbb334f83fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22946 entries, 0 to 10874\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   INDEX                     22946 non-null  int64  \n",
      " 1   LINK                      12071 non-null  object \n",
      " 2   INTEIRO_TEOR              22946 non-null  object \n",
      " 3   DATA                      22946 non-null  object \n",
      " 4   RELATOR                   22946 non-null  object \n",
      " 5   ORGAO                     22946 non-null  object \n",
      " 6   RECORRENTE                22946 non-null  object \n",
      " 7   DISPOSITIVO               22946 non-null  object \n",
      " 8   QTD_RECORRENTES           22946 non-null  float64\n",
      " 9   TRIBUNAL                  22946 non-null  object \n",
      " 10  tipo_requerente_previsto  22946 non-null  int64  \n",
      " 11  deferimento_previsto      22946 non-null  int64  \n",
      "dtypes: float64(1), int64(3), object(8)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tudo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9342ac20-57a7-4e32-8166-45c703ac43c2",
   "metadata": {},
   "source": [
    "# Salvamento da base de dados final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "963adaf1-ffc9-440a-b5ea-b035a1d6f7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tudo.to_csv(\"df_classificado.csv\", encoding='utf-8', index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cab64b-c3c4-4045-b2fb-f98cbb69c3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
