{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desenvolvimento de um classificador que identifica se o dispositivo defere ou indefere determinado recurso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base de dados construida programaticamente por meio de técnica de Weak Supervision com Snorkel Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorítmos clássicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22471 entries, 0 to 22470\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   INDEX            22471 non-null  int64  \n",
      " 1   LINK             11731 non-null  object \n",
      " 2   INTEIRO_TEOR     22471 non-null  object \n",
      " 3   DATA             22471 non-null  object \n",
      " 4   RELATOR          22471 non-null  object \n",
      " 5   ORGAO            22471 non-null  object \n",
      " 6   RECORRENTE       22471 non-null  object \n",
      " 7   DISPOSITIVO      22471 non-null  object \n",
      " 8   QTD_RECORRENTES  22471 non-null  float64\n",
      " 9   TRIBUNAL         22471 non-null  object \n",
      " 10  LABEL_WEAK       22471 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "arquivo = \"..//..//..//3_Preparacao_dos_dados//3_4_Anotacao_automatica//df_weak_supervision.csv\"\n",
    "df_tudo = pd.read_csv( arquivo, encoding='utf-8' )\n",
    "df_tudo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustes, limpeza e transformação dos rótulos para inteiros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fiz isso para evitar problemas, pois já tive problemas, e cfm mencionado no link abaixo, parece q há classes do Sklearn que funcionam com texto e outras não, além do problema q eu passei com os pacotes instalados com o Conda que parece que funcionam diferente do que instalados pelo Pip.\n",
    "https://stackoverflow.com/questions/50201315/is-numerical-encoding-necessary-for-the-target-variable-in-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEFERIMENTO = 0\n",
    "DEFERIMENTO = 1\n",
    "SEM_ANALISE_MERITO = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#limpeza de caracteres em branco\n",
    "df_tudo[\"DISPOSITIVO\"] = df_tudo[\"DISPOSITIVO\"].astype(str).map(str.strip)\n",
    "df_tudo[\"LABEL_WEAK\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12000\n",
       "1     9923\n",
       "2      548\n",
       "Name: LABEL_WEAK, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tudo[\"LABEL_WEAK\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tudo[\"LABEL_WEAK\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizador de palavras da lingua portuguesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m spacy download pt_core_news_sm\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize the given sentence in Portuguese.\n",
    "    :param text: text to be tokenized, as a string\n",
    "    \"\"\"\n",
    "    tokenizer_regexp = r'''(?ux)\n",
    "    # the order of the patterns is important!!\n",
    "    # more structured patterns come first\n",
    "    [a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+(?:\\.[a-zA-Z0-9-]+)+|    # emails\n",
    "    (?:https?://)?\\w{2,}(?:\\.\\w{2,})+(?:/\\w+)*|                  # URLs\n",
    "    (?:[\\#@]\\w+)|                     # Hashtags and twitter user names\n",
    "    (?:[^\\W\\d_]\\.)+|                  # one letter abbreviations, e.g. E.U.A.\n",
    "    (?:[DSds][Rr][Aa]?)\\.|            # common abbreviations such as dr., sr., sra., dra.\n",
    "    (?:\\B-)?\\d+(?:[:.,]\\d+)*(?:-?\\w)*|\n",
    "        # numbers in format 999.999.999,999, possibly followed by hyphen and alphanumerics\n",
    "        # \\B- avoids picks as F-14 as a negative number\n",
    "    \\.{3,}|                           # ellipsis or sequences of dots\n",
    "    \\w+|                              # alphanumerics\n",
    "    -+|                               # any sequence of dashes\n",
    "    \\S                                # any non-space character\n",
    "    '''\n",
    "    tokenizer = RegexpTokenizer(tokenizer_regexp)\n",
    "\n",
    "    return tokenizer.tokenize(text)\n",
    "\n",
    "class PortugueseTokenizer(object):\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __call__(self, text):\n",
    "        words = tokenize( text )\n",
    "        # All tokens 'own' a subsequent space character in this tokenizer\n",
    "        spaces = [True] * len(words)\n",
    "        return Doc(self.vocab, words=words, spaces=spaces)\n",
    "\n",
    "nlp.tokenizer = PortugueseTokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words = stopwords[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'a',\n",
       " 'o',\n",
       " 'que',\n",
       " 'e',\n",
       " 'é',\n",
       " 'do',\n",
       " 'da',\n",
       " 'em',\n",
       " 'um',\n",
       " 'para',\n",
       " 'com',\n",
       " 'uma',\n",
       " 'os',\n",
       " 'no',\n",
       " 'se',\n",
       " 'na',\n",
       " 'por',\n",
       " 'mais',\n",
       " 'as',\n",
       " 'dos',\n",
       " 'como',\n",
       " 'mas',\n",
       " 'ao',\n",
       " 'ele',\n",
       " 'das',\n",
       " 'à',\n",
       " 'seu',\n",
       " 'sua',\n",
       " 'ou',\n",
       " 'quando',\n",
       " 'muito',\n",
       " 'nos',\n",
       " 'já',\n",
       " 'eu',\n",
       " 'também',\n",
       " 'só',\n",
       " 'pelo',\n",
       " 'pela',\n",
       " 'até',\n",
       " 'isso',\n",
       " 'ela',\n",
       " 'entre',\n",
       " 'depois',\n",
       " 'sem',\n",
       " 'mesmo',\n",
       " 'aos',\n",
       " 'seus',\n",
       " 'quem',\n",
       " 'nas',\n",
       " 'me',\n",
       " 'esse',\n",
       " 'eles',\n",
       " 'você',\n",
       " 'essa',\n",
       " 'num',\n",
       " 'nem',\n",
       " 'suas',\n",
       " 'meu',\n",
       " 'às',\n",
       " 'minha',\n",
       " 'numa',\n",
       " 'pelos',\n",
       " 'elas',\n",
       " 'qual',\n",
       " 'nós',\n",
       " 'lhe',\n",
       " 'deles',\n",
       " 'essas',\n",
       " 'esses',\n",
       " 'pelas',\n",
       " 'este',\n",
       " 'dele',\n",
       " 'tu',\n",
       " 'te',\n",
       " 'vocês',\n",
       " 'vos',\n",
       " 'lhes',\n",
       " 'meus',\n",
       " 'minhas',\n",
       " 'teu',\n",
       " 'tua',\n",
       " 'teus',\n",
       " 'tuas',\n",
       " 'nosso',\n",
       " 'nossa',\n",
       " 'nossos',\n",
       " 'nossas',\n",
       " 'dela',\n",
       " 'delas',\n",
       " 'esta',\n",
       " 'estes',\n",
       " 'estas',\n",
       " 'aquele',\n",
       " 'aquela',\n",
       " 'aqueles',\n",
       " 'aquelas',\n",
       " 'isto',\n",
       " 'aquilo']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#codigo para tirar o \"não\" das stop words pq eu preciso dele nas funções de rotulação\n",
    "if \"não\" in nlp.Defaults.stop_words:\n",
    "    nlp.Defaults.stop_words.remove(\"não\")\n",
    "if \"dar\" in nlp.Defaults.stop_words:\n",
    "    nlp.Defaults.stop_words.remove(\"dar\")\n",
    "nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alterada esss funcao para tbm remover as stop words\n",
    "def get_lemma_form( frase ):\n",
    "    juntado = \"\"\n",
    "    for t in nlp( str( frase ) ):\n",
    "        if not t.is_stop: #remove stop words tbm\n",
    "            juntado += t.lemma_ +\" \"\n",
    "    return juntado.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#esse assert da erro, por isso eu criei a funcao limpa() abaixo.\n",
    "#assert \"dar parcial provimento\" in get_lemma_form( \"deu-se parcial provimento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ajuda a remover traços do texto\n",
    "def limpa( frase ):\n",
    "    import re\n",
    "    cleanString = re.sub('\\W+',' ', frase )\n",
    "    novo = \"\"\n",
    "    for w in cleanString.split( \" \" ):\n",
    "        pronomes_obliquos = [ \"me\", \"te\", \"se\", \"lhe\", \"lhes\", \"nos\", \"vos\" ]\n",
    "        if w not in pronomes_obliquos:\n",
    "            novo += \" \"+w\n",
    "    return novo.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_tudo(frase):\n",
    "    return limpa( get_lemma_form( frase ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer( texto ):\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    texto = nlp( str( texto ) )\n",
    "    return [ limpa_tudo( word.lemma_.lower().strip() ) if word.lemma_ != \"-PRON-\" else word.lower_ for word in texto ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes das funções de limpeza de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'dar provimento' in limpa_tudo( \"dar provimento\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'dar parcial provimento' in limpa_tudo(\"dar parcial provimento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento com tokenizador e vetorização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 122 µs, sys: 22 µs, total: 144 µs\n",
      "Wall time: 150 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "text_transform_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer=tokenizer)), \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Executar quando quiser criar a estrutura de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data_tranformed_ws = text_transform_pipeline.fit_transform(df_tudo[\"DISPOSITIVO\"].values )\n",
    "data_tranformed_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(text_transform_pipeline, 'ml_text_transform_pipeline_ws_tudo.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Executar quando quiser carregar da memoria a estrutura de dados ja criada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "text_transform_pipeline = load('ml_text_transform_pipeline_ws_tudo.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data_tranformed_ws = text_transform_pipeline.transform(df_tudo[\"DISPOSITIVO\"].values )\n",
    "data_tranformed_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação da base para testes finais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30% para testes finais. 70% para treinamento por meio de Cross Validation em 7 camadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_tranformed_ws, df_tudo[\"LABEL_WEAK\"].values, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_train: \"+str(len(y_train)))\n",
    "print(\"y_test: \"+str(len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de bibliotecas e definição de variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/model_evaluation.html#precision-recall-f-measure-metrics\n",
    "#https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin\n",
    "#https://towardsdatascience.com/confusion-matrix-for-your-multi-class-machine-learning-model-ff9aa3bf7826\n",
    "#https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "medias_cv = pd.DataFrame( )\n",
    "\n",
    "def treinar_cv(model, nome_classificador):\n",
    "    conf_matrix_list_of_arrays = []\n",
    "    metricas_modelo = []\n",
    "    cv = 7\n",
    "    kf = KFold(n_splits=cv, random_state=0, shuffle=True)\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "\n",
    "        X_train_cv = X_train[train_index]\n",
    "        X_test_cv = X_train[test_index]\n",
    "        y_train_cv = y_train[train_index]\n",
    "        y_test_cv = y_train[test_index]\n",
    "\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "        y_predicted = model.predict(X_test_cv)\n",
    "\n",
    "        #METRICAS\n",
    "        accuracy = accuracy_score(y_test_cv, y_predicted)\n",
    "        f1_macro = f1_score(y_test_cv, y_predicted, average='macro')\n",
    "        f1_micro = f1_score(y_test_cv, y_predicted, average='micro')\n",
    "        precision_macro = precision_score(y_test_cv, y_predicted, average='macro')\n",
    "        precision_micro = precision_score(y_test_cv, y_predicted, average='micro')\n",
    "        recall_macro = recall_score(y_test_cv, y_predicted, average='macro')\n",
    "        recall_micro = recall_score(y_test_cv, y_predicted, average='micro')\n",
    "\n",
    "        metricas_cv = [accuracy, f1_macro, precision_macro, recall_macro, f1_micro, precision_micro, recall_micro]\n",
    "        metricas_modelo.append( metricas_cv ) \n",
    "\n",
    "        #confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_test_cv, y_predicted, labels=[INDEFERIMENTO, DEFERIMENTO, SEM_ANALISE_MERITO])\n",
    "        conf_matrix_list_of_arrays.append(conf_matrix)\n",
    "        \n",
    "    #calcula media da Confusion matrix\n",
    "    mean_of_conf_matrix_arrays = np.mean(conf_matrix_list_of_arrays, axis=0)\n",
    "    cm = mean_of_conf_matrix_arrays\n",
    "    \n",
    "    #grafico\n",
    "    x = [\"INDEFERIMENTO\", \"DEFERIMENTO\", \"SEM_ANALISE_MERITO\"]\n",
    "    y = [\"INDEFERIMENTO\", \"DEFERIMENTO\", \"SEM_ANALISE_MERITO\"]\n",
    "\n",
    "    fig = ff.create_annotated_heatmap(cm.round(4), x=x, y=y, annotation_text=cm.round(4), colorscale='Blues')\n",
    "    fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "    iplot(fig)\n",
    "    \n",
    "    #tira a media de todas as camadas do cv\n",
    "    metricas_modelo_media = np.mean(metricas_modelo, axis=0).tolist()\n",
    "    metricas_modelo_media.insert(0, nome_classificador)\n",
    "    print(\"\")\n",
    "    print(metricas_modelo_media)\n",
    "    \n",
    "    return metricas_modelo_media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rocchio classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "metricas = treinar_cv(NearestCentroid(), \"Rocchio classifier\")\n",
    "medias_cv = medias_cv.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "metricas = treinar_cv(GradientBoostingClassifier(n_estimators=100), \"Gradient Boosting Classifier\")\n",
    "medias_cv = medias_cv.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "metricas = treinar_cv(MultinomialNB(), \"Naive Bayes\")\n",
    "medias_cv = medias_cv.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "metricas = treinar_cv(KNeighborsClassifier(), \"K-nearest Neighbor\")\n",
    "medias_cv = medias_cv.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "metricas = treinar_cv(LinearSVC(), \"Support Vector Machine (SVM)\")\n",
    "medias_cv = medias_cv.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "metricas = treinar_cv(tree.DecisionTreeClassifier(), \"Decision Tree\")\n",
    "medias_cv = medias_cv.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "metricas = treinar_cv(RandomForestClassifier(n_estimators=100), \"Random Forest\")\n",
    "medias_cv = medias_cv.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = [\"Classificador\", \"Acurácia\", \"F1 macro\", \"Precisão macro\", \"Revocação macro\", \"F1 micro\", \"Precisão micro\", \"Revocação micro\"]\n",
    "medias_cv.columns = colunas\n",
    "medias_cv = medias_cv.set_index(\"Classificador\")\n",
    "medias_cv = medias_cv.round(4)\n",
    "medias_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iplot( { \"data\": [ go.Scatter(x=colunas[1:], y=medias_cv.iloc[i,:], name=medias_cv.index[i] ) for i in range( len( medias_cv ) ) ] } )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste final com base de 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medias_teste_final = pd.DataFrame( )\n",
    "\n",
    "def treinar_teste_final(model, nome_classificador):\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_predicted = model.predict(X_test)\n",
    "\n",
    "    ####################\n",
    "    #metricas\n",
    "    ####################    \n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    f1_macro = f1_score(y_test, y_predicted, average='macro')\n",
    "    f1_micro = f1_score(y_test, y_predicted, average='micro')\n",
    "    precision_macro = precision_score(y_test, y_predicted, average='macro')\n",
    "    precision_micro = precision_score(y_test, y_predicted, average='micro')\n",
    "    recall_macro = recall_score(y_test, y_predicted, average='macro')\n",
    "    recall_micro = recall_score(y_test, y_predicted, average='micro')\n",
    "\n",
    "    \n",
    "    metricas_modelo = [accuracy, f1_macro, precision_macro, recall_macro, f1_micro, precision_micro, recall_micro]\n",
    "    metricas_modelo.insert(0, nome_classificador)\n",
    "    print(metricas_modelo)\n",
    "\n",
    "    ####################\n",
    "    #confusion matrix\n",
    "    ####################    \n",
    "    conf_matrix = confusion_matrix(y_test, y_predicted, labels=[INDEFERIMENTO, DEFERIMENTO, SEM_ANALISE_MERITO])\n",
    "    cm = conf_matrix\n",
    "    \n",
    "    #grafico\n",
    "    x = [\"INDEFERIMENTO\", \"DEFERIMENTO\", \"SEM_ANALISE_MERITO\"]\n",
    "    y = [\"INDEFERIMENTO\", \"DEFERIMENTO\", \"SEM_ANALISE_MERITO\"]\n",
    "\n",
    "    fig = ff.create_annotated_heatmap(cm.round(4), x=x, y=y, annotation_text=cm.round(4), colorscale='Blues')\n",
    "    fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "    iplot(fig)\n",
    "\n",
    "    return metricas_modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rocchio classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "metricas = treinar_teste_final(NearestCentroid(), \"Rocchio classifier\")\n",
    "medias_teste_final = medias_teste_final.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "metricas = treinar_teste_final(GradientBoostingClassifier(n_estimators=100), \"Gradient Boosting Classifier\")\n",
    "medias_teste_final = medias_teste_final.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "metricas = treinar_teste_final(MultinomialNB(), \"Naive Bayes\")\n",
    "medias_teste_final = medias_teste_final.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "metricas = treinar_teste_final(KNeighborsClassifier(), \"K-nearest Neighbor\")\n",
    "medias_teste_final = medias_teste_final.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "metricas = treinar_teste_final(LinearSVC(), \"Support Vector Machine (SVM)\")\n",
    "medias_teste_final = medias_teste_final.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "metricas = treinar_teste_final(tree.DecisionTreeClassifier(), \"Decision Tree\")\n",
    "medias_teste_final = medias_teste_final.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "metricas = treinar_teste_final(RandomForestClassifier(n_estimators=100), \"Random Forest\")\n",
    "medias_teste_final = medias_teste_final.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = [\"Classificador\", \"Acurácia\", \"F1 macro\", \"Precisão macro\", \"Revocação macro\", \"F1 micro\", \"Precisão micro\", \"Revocação micro\"]\n",
    "medias_teste_final.columns = colunas\n",
    "medias_teste_final = medias_teste_final.set_index(\"Classificador\")\n",
    "medias_teste_final = medias_teste_final.round(4)\n",
    "medias_teste_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medias_teste_final.to_excel(\"medias_teste_final_contra_30_ws_todo.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iplot( { \"data\": [ go.Scatter(x=colunas[1:], y=medias_teste_final.iloc[i,:], name=medias_teste_final.index[i] ) for i in range( len( medias_teste_final ) ) ] } )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste com a base padrão-ouro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = \"..//..//..//3_Preparacao_dos_dados//3_2_Anotacao_manual//Datasets_anotados_manual_final//Decisões anotação manual - ADJUDICADO.csv\"\n",
    "df_padrao_ouro = pd.read_csv( arquivo, encoding='utf-8' )\n",
    "df_padrao_ouro.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajustes, limpeza e transformação dos rótulos para inteiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpeza de caracteres em branco\n",
    "df_padrao_ouro[\"DISPOSITIVO\"] = df_padrao_ouro[\"DISPOSITIVO\"].astype(str).map(str.strip)\n",
    "df_padrao_ouro[\"ROTULO\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_padrao_ouro[\"ROTULO\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#primeiro tem q substituir INDEFERIMENTO pq se nao fizer DEFERIMENTO antes ele acaba subtituindo no meio da palavra.\n",
    "df_padrao_ouro['ROTULO'] = df_padrao_ouro['ROTULO'].replace('INDEFERIMENTO', INDEFERIMENTO)\n",
    "df_padrao_ouro['ROTULO'] = df_padrao_ouro['ROTULO'].replace('DEFERIMENTO', DEFERIMENTO)\n",
    "df_padrao_ouro['ROTULO'] = df_padrao_ouro['ROTULO'].replace('SEM_ANALISE_MERITO', SEM_ANALISE_MERITO)\n",
    "df_padrao_ouro[\"ROTULO\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_padrao_ouro[\"ROTULO\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_padrao_ouro[\"ROTULO\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tranformed_padrao_ouro = text_transform_pipeline.transform(df_padrao_ouro[\"DISPOSITIVO\"].values )\n",
    "data_tranformed_padrao_ouro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_padrao_ouro[\"ROTULO\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retreinamento com toda a base de dados criada programaticamente para buscar alcançar o melhor modelo possível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medias_teste_padrao_ouro = pd.DataFrame( )\n",
    "\n",
    "X_test = data_tranformed_padrao_ouro\n",
    "y_test = df_padrao_ouro[\"ROTULO\"].values\n",
    "\n",
    "def treinar_teste_padrao_ouro(model, nome_classificador):\n",
    "    model.fit(data_tranformed_ws, df_tudo[\"LABEL_WEAK\"].values)\n",
    "    y_predicted = model.predict(X_test)\n",
    "\n",
    "    ####################\n",
    "    #metricas\n",
    "    ####################    \n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    f1_macro = f1_score(y_test, y_predicted, average='macro')\n",
    "    f1_micro = f1_score(y_test, y_predicted, average='micro')\n",
    "    precision_macro = precision_score(y_test, y_predicted, average='macro')\n",
    "    precision_micro = precision_score(y_test, y_predicted, average='micro')\n",
    "    recall_macro = recall_score(y_test, y_predicted, average='macro')\n",
    "    recall_micro = recall_score(y_test, y_predicted, average='micro')\n",
    "\n",
    "    \n",
    "    metricas_modelo = [accuracy, f1_macro, precision_macro, recall_macro, f1_micro, precision_micro, recall_micro]\n",
    "    metricas_modelo.insert(0, nome_classificador)\n",
    "    print(metricas_modelo)\n",
    "\n",
    "    ####################\n",
    "    #confusion matrix\n",
    "    ####################    \n",
    "    conf_matrix = confusion_matrix(y_test, y_predicted, labels=[INDEFERIMENTO, DEFERIMENTO, SEM_ANALISE_MERITO])\n",
    "    cm = conf_matrix\n",
    "    \n",
    "    #grafico\n",
    "    x = [\"INDEFERIMENTO\", \"DEFERIMENTO\", \"SEM_ANALISE_MERITO\"]\n",
    "    y = [\"INDEFERIMENTO\", \"DEFERIMENTO\", \"SEM_ANALISE_MERITO\"]\n",
    "\n",
    "    fig = ff.create_annotated_heatmap(cm.round(4), x=x, y=y, annotation_text=cm.round(4), colorscale='Blues')\n",
    "    fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "    iplot(fig)\n",
    "\n",
    "    return metricas_modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rocchio classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "metricas = treinar_teste_padrao_ouro(NearestCentroid(), \"Rocchio classifier\")\n",
    "medias_teste_padrao_ouro = medias_teste_padrao_ouro.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "metricas = treinar_teste_padrao_ouro(GradientBoostingClassifier(n_estimators=100), \"Gradient Boosting Classifier\")\n",
    "medias_teste_padrao_ouro = medias_teste_padrao_ouro.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "metricas = treinar_teste_padrao_ouro(MultinomialNB(), \"Naive Bayes\")\n",
    "medias_teste_padrao_ouro = medias_teste_padrao_ouro.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "metricas = treinar_teste_padrao_ouro(KNeighborsClassifier(), \"K-nearest Neighbor\")\n",
    "medias_teste_padrao_ouro = medias_teste_padrao_ouro.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "metricas = treinar_teste_padrao_ouro(LinearSVC(), \"Support Vector Machine (SVM)\")\n",
    "medias_teste_padrao_ouro = medias_teste_padrao_ouro.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "metricas = treinar_teste_padrao_ouro(tree.DecisionTreeClassifier(), \"Decision Tree\")\n",
    "medias_teste_padrao_ouro = medias_teste_padrao_ouro.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "metricas = treinar_teste_padrao_ouro(RandomForestClassifier(n_estimators=100), \"Random Forest\")\n",
    "medias_teste_padrao_ouro = medias_teste_padrao_ouro.append( [metricas] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = [\"Classificador\", \"Acurácia\", \"F1 macro\", \"Precisão macro\", \"Revocação macro\", \"F1 micro\", \"Precisão micro\", \"Revocação micro\"]\n",
    "medias_teste_padrao_ouro.columns = colunas\n",
    "medias_teste_padrao_ouro = medias_teste_padrao_ouro.set_index(\"Classificador\")\n",
    "medias_teste_padrao_ouro = medias_teste_padrao_ouro.round(4)\n",
    "medias_teste_padrao_ouro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medias_teste_padrao_ouro.to_excel(\"medias_teste_final_contra_padrao_ouro_ws_todo.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iplot( { \"data\": [ go.Scatter(x=colunas[1:], y=medias_teste_padrao_ouro.iloc[i,:], name=medias_teste_padrao_ouro.index[i] ) for i in range( len( medias_teste_padrao_ouro ) ) ] } )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retreinamento do classificador que teve a melhor métrica de F1 com a base de dados padrão-ouro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo Decision Tree e Gradient Boosting Classifier tiveram a mesma média de F1, então foi escolhido o Decision Tree devido a sua melhor interpretabilidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = RandomForestClassifier(n_estimators=100).fit(data_tranformed_ws, df_tudo[\"LABEL_WEAK\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvamento do modelo para utilização posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(text_clf, 'ml_model_dispositivo_Random_Forest_ws_tudo.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
